{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0lUxDMkIXli2QyStUgSMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaGordienko1/NLP/blob/main/NLP3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Выпонение лабораторной работы 3"
      ],
      "metadata": {
        "id": "ifHrPiEfwxDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 часть"
      ],
      "metadata": {
        "id": "qH6IXrTRxYCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт библиотек ⭐"
      ],
      "metadata": {
        "id": "MgF8kFLpw-Zd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E-4r64E0n8mz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функция линейной регрессии"
      ],
      "metadata": {
        "id": "p69EPogrfs5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression(X: np.ndarray) -> float:\n",
        "\n",
        "    weight = np.random.randn()\n",
        "    bias = np.random.randn()\n",
        "\n",
        "    return float(X * weight + bias)"
      ],
      "metadata": {
        "id": "Or2Awck3pBMQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функция активации: сигмоида\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xLV9X_HFxakf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_func(x: float) -> float:\n",
        "\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "CpgjmuuJoR0h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Нейрон\n",
        "\n"
      ],
      "metadata": {
        "id": "99LSUbXXyiTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron(x: np.ndarray):\n",
        "\n",
        "    temp_result = linear_regression(x)\n",
        "    result = activation_func(temp_result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "8gbx1S1zobpP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Применение на датасете"
      ],
      "metadata": {
        "id": "kYJ1Nj17y4It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Mall_Customers.csv\")\n",
        "\n",
        "X = df['Annual Income (k$)'].values\n",
        "Y = df['Spending Score (1-100)'].values\n",
        "\n",
        "x_sample = X[0]\n",
        "\n",
        "output = neuron(x_sample)\n",
        "print(f\"Входное значение X: {x_sample}, Выход нейрона: {output}\")"
      ],
      "metadata": {
        "id": "Vyxmn9fSoemS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb3b9a1-3921-425f-a2ec-72f039c50f11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входное значение X: 15, Выход нейрона: 8.824849190884547e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 часть"
      ],
      "metadata": {
        "id": "5gb-brH3xhCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорт, активация, нормализация"
      ],
      "metadata": {
        "id": "8abVnulL1c6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def activation_func(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def activation_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def normalize(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n"
      ],
      "metadata": {
        "id": "lj44W7j51yLc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Класс с возможностью задать количество нейронов слоя и произвести обучение"
      ],
      "metadata": {
        "id": "LSzgvY9T2IBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size, learning_rate=0.01):\n",
        "        np.random.seed(42)\n",
        "        self.lr = learning_rate\n",
        "\n",
        "        self.W1 = np.random.randn(input_size, hidden1_size) * 0.1\n",
        "        self.b1 = np.zeros((1, hidden1_size))\n",
        "        self.W2 = np.random.randn(hidden1_size, hidden2_size) * 0.1\n",
        "        self.b2 = np.zeros((1, hidden2_size))\n",
        "        self.W3 = np.random.randn(hidden2_size, output_size) * 0.1\n",
        "        self.b3 = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = activation_func(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        self.a2 = activation_func(self.z2)\n",
        "        self.z3 = np.dot(self.a2, self.W3) + self.b3\n",
        "        self.a3 = activation_func(self.z3)\n",
        "        return self.a3\n",
        "\n",
        "    def backward(self, X, y):\n",
        "        m = X.shape[0]\n",
        "\n",
        "        dZ3 = self.a3 - y\n",
        "        dW3 = np.dot(self.a2.T, dZ3) / m\n",
        "        db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
        "\n",
        "        dZ2 = np.dot(dZ3, self.W3.T) * activation_derivative(self.a2)\n",
        "        dW2 = np.dot(self.a1.T, dZ2) / m\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "        dZ1 = np.dot(dZ2, self.W2.T) * activation_derivative(self.a1)\n",
        "        dW1 = np.dot(X.T, dZ1) / m\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "        self.W3 -= self.lr * dW3\n",
        "        self.b3 -= self.lr * db3\n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "\n",
        "    def train(self, X, y, epochs):\n",
        "        for epoch in range(epochs):\n",
        "            self.forward(X)\n",
        "            self.backward(X, y)\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean((y - self.a3) ** 2)\n",
        "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n"
      ],
      "metadata": {
        "id": "sLC4K1fBxlNz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проверка\n",
        "\n"
      ],
      "metadata": {
        "id": "MxN3KRAG3bHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Mall_Customers.csv\")\n",
        "\n",
        "X_raw = df['Annual Income (k$)'].values.reshape(-1, 1)\n",
        "Y_raw = df['Spending Score (1-100)'].values.reshape(-1, 1)\n",
        "\n",
        "X_normalized = normalize(X_raw)\n",
        "Y_normalized = normalize(Y_raw)\n",
        "\n",
        "input_size = 1\n",
        "hidden1_size = 5\n",
        "hidden2_size = 5\n",
        "output_size = 1\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "nn = NeuralNetwork(input_size, hidden1_size, hidden2_size, output_size, learning_rate)\n",
        "nn.train(X_normalized, Y_normalized, epochs)\n",
        "\n",
        "predictions = nn.forward(X_normalized)\n",
        "\n",
        "print(\"Настоящее значение:\", Y_raw.flatten()[:5])\n",
        "print(\"Предсказание:\", (predictions * 100).flatten()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuMRzmXA3fiL",
        "outputId": "e5640d60-c07f-4e46-a079-7480a33d4352"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.0692\n",
            "Epoch 100, Loss: 0.0691\n",
            "Epoch 200, Loss: 0.0691\n",
            "Epoch 300, Loss: 0.0691\n",
            "Epoch 400, Loss: 0.0691\n",
            "Epoch 500, Loss: 0.0691\n",
            "Epoch 600, Loss: 0.0691\n",
            "Epoch 700, Loss: 0.0691\n",
            "Epoch 800, Loss: 0.0691\n",
            "Epoch 900, Loss: 0.0691\n",
            "Настоящее значение: [39 81  6 77 40]\n",
            "Предсказание: [50.20817834 50.20817834 50.20819002 50.20819002 50.2082017 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Применение"
      ],
      "metadata": {
        "id": "AjK2sZl55p3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(X, Y):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    input_size = X_train.shape[1]\n",
        "    hidden1_size = 5\n",
        "    hidden2_size = 5\n",
        "    output_size = 1\n",
        "    learning_rate = 0.01\n",
        "    epochs = 1000\n",
        "\n",
        "    model = NeuralNetwork(input_size, hidden1_size, hidden2_size, output_size, learning_rate)\n",
        "    model.train(X_train, Y_train, epochs)\n",
        "\n",
        "    Y_train_pred = model.forward(X_train)\n",
        "    Y_train_pred_binary = (Y_train_pred > 0.5).astype(int)\n",
        "    Y_train_binary = (Y_train > 0.5).astype(int)\n",
        "    train_accuracy = accuracy_score(Y_train_binary, Y_train_pred_binary)\n",
        "\n",
        "    Y_test_pred = model.forward(X_test)\n",
        "    Y_test_pred_binary = (Y_test_pred > 0.5).astype(int)\n",
        "    Y_test_binary = (Y_test > 0.5).astype(int)\n",
        "    test_accuracy = accuracy_score(Y_test_binary, Y_test_pred_binary)\n",
        "\n",
        "    print(f\"Точность на обучающей выборке: {train_accuracy:.4f}\")\n",
        "    print(f\"Точность на тестовой выборке: {test_accuracy:.4f}\")\n",
        "    print(\"\\n Отчет классификации на тестовой выборке:\")\n",
        "    print(classification_report(Y_test_binary, Y_test_pred_binary))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = train_and_evaluate(X_normalized, Y_normalized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl9QPBRh5olQ",
        "outputId": "9a3a7f9d-5c8c-4ceb-d7a6-1529fc2fa19c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.0723\n",
            "Epoch 100, Loss: 0.0722\n",
            "Epoch 200, Loss: 0.0722\n",
            "Epoch 300, Loss: 0.0722\n",
            "Epoch 400, Loss: 0.0722\n",
            "Epoch 500, Loss: 0.0722\n",
            "Epoch 600, Loss: 0.0722\n",
            "Epoch 700, Loss: 0.0722\n",
            "Epoch 800, Loss: 0.0722\n",
            "Epoch 900, Loss: 0.0722\n",
            "Точность на обучающей выборке: 0.5000\n",
            "Точность на тестовой выборке: 0.4250\n",
            "\n",
            " Отчет классификации на тестовой выборке:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.42      1.00      0.60        17\n",
            "\n",
            "    accuracy                           0.42        40\n",
            "   macro avg       0.21      0.50      0.30        40\n",
            "weighted avg       0.18      0.42      0.25        40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 часть"
      ],
      "metadata": {
        "id": "JtRp2uwcIImk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Реализация GPT"
      ],
      "metadata": {
        "id": "MAFYIOFhIg6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Head:\n",
        "\n",
        "    def __init__(self, embedding_dim, attention_dim, seq_len, drop_rate):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.attention_dim = attention_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "        self.key_matrix = np.random.randn(embedding_dim, attention_dim) * 0.1\n",
        "        self.query_matrix = np.random.randn(embedding_dim, attention_dim) * 0.1\n",
        "        self.value_matrix = np.random.randn(embedding_dim, attention_dim) * 0.1\n",
        "\n",
        "        self.mask_matrix = np.tril(np.ones((seq_len, seq_len)))\n",
        "\n",
        "    def compute(self, input_tensor):\n",
        "        B, T, C = input_tensor.shape\n",
        "\n",
        "        key_proj = np.dot(input_tensor, self.key_matrix)    # (B, T, hs)\n",
        "        query_proj = np.dot(input_tensor, self.query_matrix)  # (B, T, hs)\n",
        "\n",
        "        attention_scores = np.matmul(query_proj, key_proj.transpose(0, 2, 1)) * (key_proj.shape[-1] ** -0.5)  # (B, T, T)\n",
        "        attention_scores = np.where(self.mask_matrix[:T, :T] == 0, float('-inf'), attention_scores)  # (B, T, T)\n",
        "        exp_scores = np.exp(attention_scores - np.max(attention_scores, axis=-1, keepdims=True))\n",
        "        attention_weights = exp_scores / np.sum(exp_scores, axis=-1, keepdims=True)  # (B, T, T)\n",
        "\n",
        "        dropout_mask = np.random.rand(*attention_weights.shape) > self.drop_rate\n",
        "        attention_weights = attention_weights * dropout_mask\n",
        "\n",
        "        value_proj = np.dot(input_tensor, self.value_matrix)  # (B, T, hs)\n",
        "        output_tensor = np.matmul(attention_weights, value_proj)  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "\n",
        "        return output_tensor\n",
        "\n",
        "embedding_dim = 128\n",
        "attention_dim = 32\n",
        "seq_len = 64\n",
        "drop_rate = 0.1\n",
        "\n",
        "attention_head = Head(embedding_dim, attention_dim, seq_len, drop_rate)\n",
        "\n",
        "batch_size = 4\n",
        "time_steps = 16\n",
        "channels = embedding_dim\n",
        "input_data = np.random.randn(batch_size, time_steps, channels)\n",
        "\n",
        "result = attention_head.compute(input_data)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAP1IX85IQOZ",
        "outputId": "b631a67a-74a8-4f52-e936-7961ed194a98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.96816358  0.75093197 -1.08417396 ...  0.53711862  0.13297851\n",
            "   -0.01480837]\n",
            "  [-0.28324814 -0.1436078  -0.0991582  ...  0.74659862 -2.19628869\n",
            "    0.02039824]\n",
            "  [-0.04814912  0.01263255 -0.00774346 ...  0.00336655  0.00739636\n",
            "    0.01384436]\n",
            "  ...\n",
            "  [ 0.07049248  0.6866702  -0.25333423 ... -1.09523656 -0.64059144\n",
            "    0.09285656]\n",
            "  [ 0.74155093 -0.09682823 -1.22513782 ... -1.0343882  -0.49598267\n",
            "    0.07865018]\n",
            "  [-0.43750086  0.4645297   0.46725375 ... -0.50024581  0.25711065\n",
            "    0.35748516]]\n",
            "\n",
            " [[-0.53964632  1.1483524   1.01436077 ...  1.33296281  1.53151465\n",
            "    0.66686896]\n",
            "  [-0.30283081  0.64441557  0.56922411 ...  0.74801254  0.85943295\n",
            "    0.37422375]\n",
            "  [-0.09596716  0.13647349  0.18464583 ...  0.15471289  0.2610533\n",
            "    0.17073862]\n",
            "  ...\n",
            "  [-0.17596198  0.25445193  0.16693777 ... -0.23102146  0.01967084\n",
            "    0.13414608]\n",
            "  [-0.07419337  0.33716137  0.22970324 ... -0.03382462  0.0094408\n",
            "   -0.29776796]\n",
            "  [-0.25506992 -0.17126381  0.00967381 ...  0.08799204 -0.52682791\n",
            "   -0.02999064]]\n",
            "\n",
            " [[ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [-0.69333421 -0.29444788  0.44224794 ...  0.51787265 -0.37135729\n",
            "   -1.38395711]\n",
            "  [-0.87650256 -0.4433979  -0.47413336 ...  0.77689703 -0.41720603\n",
            "   -0.05296623]\n",
            "  ...\n",
            "  [ 0.33769022  0.67982978 -0.13876732 ... -0.4337285  -0.0181868\n",
            "   -0.1750203 ]\n",
            "  [ 0.08440486  0.75273233 -0.41352635 ...  0.18122068 -1.09646667\n",
            "    0.35758435]\n",
            "  [-0.10874226  0.79102613 -0.31628812 ...  0.08960475 -0.46191891\n",
            "    0.29458647]]\n",
            "\n",
            " [[-1.16043695 -0.14680986 -0.15584127 ...  0.30466795  0.77708935\n",
            "   -0.70981571]\n",
            "  [-0.91760372 -0.78153447  0.51674028 ...  1.95886924  0.3435221\n",
            "    0.74705074]\n",
            "  [-0.71265064 -0.55417539  0.54677912 ...  1.29571421  0.30079484\n",
            "    0.07327856]\n",
            "  ...\n",
            "  [-0.01348218 -0.41935768  0.25856961 ...  0.35521668 -0.42393385\n",
            "    0.12368453]\n",
            "  [ 0.07334402 -0.07402911  0.05150108 ...  0.43514221 -0.2736743\n",
            "    0.22384285]\n",
            "  [-0.41128067  0.15424969 -0.32981414 ...  0.06143596 -1.09359361\n",
            "    0.30299625]]]\n"
          ]
        }
      ]
    }
  ]
}